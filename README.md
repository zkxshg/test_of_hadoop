# test_of_hadoop
## Test of hadoop/mapreduce/spark
1. **hadoop_env.sh**: Setup of *Hadoop*
2. **HDFS-oper.sh**: Operation on *HDFS*
3. **hive-set.sh**: Initialize of *Hive*
4. **test_air_assorRule.sh**: *FPGrowth* on *Spark* for association rule with wind and air quality
5. **test_bike_predict.sh**: *Random Forest* on *Spark* to predict the loan amount of shared bikes
6. **test_wind_predict.sh**: *Random Forest* on *Spark* to predict the generation amount of wind power
7. **GCP_kmeans.py**: *K-means* cluster on *GCP*
